\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {paragraph}{Problem:}{1}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Meinshausen-Buhlmann Method:}{1}{section*.2}}
\newlabel{eq:mb}{{1}{1}{Meinshausen-Buhlmann Method:}{equation.0.1}{}}
\newlabel{eq:glasso}{{2}{2}{Meinshausen-Buhlmann Method:}{equation.0.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Chain Graphs, Nearest Neighbor Networks and Scale-free Networks:}{2}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Algorithm:}{2}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Results:}{3}{section*.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:compare}{{1}{5}{}{table.caption.6}{}}
\newlabel{fig:fpchain}{{1a}{6}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:fpchain}{{a}{6}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.7}{}}
\newlabel{fig:Frobeniuschain}{{1b}{6}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:Frobeniuschain}{{b}{6}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plots for Proximal Gradient Algorithm for Chain Graph. $\lambda \approx 60$ seems to be optimal as both FN and FP are equal to 0 and F seems to be at its minimum point as well. \relax }}{6}{figure.caption.7}}
\newlabel{fig:chain}{{1}{6}{Plots for Proximal Gradient Algorithm for Chain Graph. $\lambda \approx 60$ seems to be optimal as both FN and FP are equal to 0 and F seems to be at its minimum point as well. \relax }{figure.caption.7}{}}
\newlabel{fig:chaingaphsestimate}{{2a}{7}{Estimated Chain Graph\relax }{figure.caption.8}{}}
\newlabel{sub@fig:chaingaphsestimate}{{a}{7}{Estimated Chain Graph\relax }{figure.caption.8}{}}
\newlabel{fig:chaingaphsactual}{{2b}{7}{True Chain Graph\relax }{figure.caption.8}{}}
\newlabel{sub@fig:chaingaphsactual}{{b}{7}{True Chain Graph\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces As we can see from the graphs, the sparstiy in the case of the chain graphs was predicted exactly.\relax }}{7}{figure.caption.8}}
\newlabel{fig:chaingraphs}{{2}{7}{As we can see from the graphs, the sparstiy in the case of the chain graphs was predicted exactly.\relax }{figure.caption.8}{}}
\newlabel{fig:fpnear}{{3a}{8}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.9}{}}
\newlabel{sub@fig:fpnear}{{a}{8}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.9}{}}
\newlabel{fig:Frobeniusnear}{{3b}{8}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.9}{}}
\newlabel{sub@fig:Frobeniusnear}{{b}{8}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plots for Proximal Gradient Algorithm for Nearest Neighbor Graph. $\lambda \approx 15$ seems to be optimal to minimize FN/FP while $\lambda \approx 30$ minimizes F.\relax }}{8}{figure.caption.9}}
\newlabel{fig:near}{{3}{8}{Plots for Proximal Gradient Algorithm for Nearest Neighbor Graph. $\lambda \approx 15$ seems to be optimal to minimize FN/FP while $\lambda \approx 30$ minimizes F.\relax }{figure.caption.9}{}}
\newlabel{fig:nearestgaphsestimate}{{4a}{9}{Estimated Nearest Neighbor Graph at $\lambda = 15$\relax }{figure.caption.10}{}}
\newlabel{sub@fig:nearestgaphsestimate}{{a}{9}{Estimated Nearest Neighbor Graph at $\lambda = 15$\relax }{figure.caption.10}{}}
\newlabel{fig:nearestgaphsestimate}{{4b}{9}{Estimated Nearest Neighbor Graph at $\lambda = 30$\relax }{figure.caption.10}{}}
\newlabel{sub@fig:nearestgaphsestimate}{{b}{9}{Estimated Nearest Neighbor Graph at $\lambda = 30$\relax }{figure.caption.10}{}}
\newlabel{fig:nearestgaphsactual}{{4c}{9}{True Nearest Neighbor Graph\relax }{figure.caption.10}{}}
\newlabel{sub@fig:nearestgaphsactual}{{c}{9}{True Nearest Neighbor Graph\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The graph shows the sparsity patterns in the estimated and actual graphs in the case of the nearest neighbor network. In this case, we were unable to recover the exact sparsity pattern.\relax }}{9}{figure.caption.10}}
\newlabel{fig:neargraph}{{4}{9}{The graph shows the sparsity patterns in the estimated and actual graphs in the case of the nearest neighbor network. In this case, we were unable to recover the exact sparsity pattern.\relax }{figure.caption.10}{}}
\newlabel{fig:fpbara}{{5a}{10}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:fpbara}{{a}{10}{False Positive/False Negative rate vs $\lambda $.\relax }{figure.caption.11}{}}
\newlabel{fig:Frobeniusbara}{{5b}{10}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.11}{}}
\newlabel{sub@fig:Frobeniusbara}{{b}{10}{Frobenius Norm Loss vs $\lambda $.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Plots for Proximal Gradient Algorithm for Scale-free Network. $\lambda \approx 15$ minimizes FN/FP while $\lambda \approx 7$ seems to minimize F .\relax }}{10}{figure.caption.11}}
\newlabel{fig:bara}{{5}{10}{Plots for Proximal Gradient Algorithm for Scale-free Network. $\lambda \approx 15$ minimizes FN/FP while $\lambda \approx 7$ seems to minimize F .\relax }{figure.caption.11}{}}
\newlabel{fig:nearestgaphsestimate}{{6a}{11}{Estimated Scale-free network Graph at $\lambda = 7$\relax }{figure.caption.12}{}}
\newlabel{sub@fig:nearestgaphsestimate}{{a}{11}{Estimated Scale-free network Graph at $\lambda = 7$\relax }{figure.caption.12}{}}
\newlabel{fig:nearestgaphsestimate}{{6b}{11}{Estimated Scale-free network Graph at $\lambda = 15$\relax }{figure.caption.12}{}}
\newlabel{sub@fig:nearestgaphsestimate}{{b}{11}{Estimated Scale-free network Graph at $\lambda = 15$\relax }{figure.caption.12}{}}
\newlabel{fig:nearestgaphsactual}{{6c}{11}{True Scale-free network Graph\relax }{figure.caption.12}{}}
\newlabel{sub@fig:nearestgaphsactual}{{c}{11}{True Scale-free network Graph\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The graph shows the sparsity patterns in the estimated and actual graphs in the case of the Scale-free network. In this case also, we were unable to recover the exact sparsity pattern.\relax }}{11}{figure.caption.12}}
\newlabel{fig:baragraph}{{6}{11}{The graph shows the sparsity patterns in the estimated and actual graphs in the case of the Scale-free network. In this case also, we were unable to recover the exact sparsity pattern.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Appendix: R Code for Proximal Gradient Algorithm}{12}{section*.13}}
